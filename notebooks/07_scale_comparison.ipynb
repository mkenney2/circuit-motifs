{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Cross-Scale Motif Analysis: Gemma 3 Family\n",
    "\n",
    "This notebook analyzes how motif enrichment patterns change across model scales\n",
    "using the Gemma 3 family (270M, 1B, 4B, 12B, 27B).\n",
    "\n",
    "**Key question:** Does the structural grammar of computation change as models get bigger?\n",
    "\n",
    "Sections:\n",
    "1. Setup & load model registry\n",
    "2. Per-model summaries (graph counts, sizes)\n",
    "3. **Scale heatmap** — main result figure\n",
    "4. **FFL backbone analysis** — 030T Z-score across scales\n",
    "5. **Scaling curves** — key motifs vs log(params)\n",
    "6. **Per-task scaling** — arithmetic, safety, reasoning separately\n",
    "7. **Phase transition detection**\n",
    "8. **Model similarity** — cosine matrix + dendrogram\n",
    "9. **SP overlay** — all models' profiles overlaid\n",
    "10. Comparison with Haiku/Gemma-2-2B/Qwen3-4B baseline\n",
    "\n",
    "**Prerequisite:** Run the scale pipeline first:\n",
    "```bash\n",
    "python -m src.pipeline --scale-mode --data-dir data/raw --results-dir data/results --n-random 100\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.models import (\n",
    "    get_model, gemma3_scaling_curve, GEMMA_3_MODELS, ALL_MODELS,\n",
    ")\n",
    "from src.motif_census import (\n",
    "    TRIAD_LABELS, CONNECTED_TRIAD_INDICES,\n",
    "    MOTIF_FFL, MOTIF_CHAIN, MOTIF_FAN_IN, MOTIF_FAN_OUT,\n",
    ")\n",
    "from src.scale_comparison import (\n",
    "    ModelProfile, ScaleComparison, ScaleTrend,\n",
    "    build_model_profile, run_scale_comparison,\n",
    "    compute_scale_trends, detect_phase_transitions,\n",
    "    pairwise_model_similarity, check_ffl_backbone,\n",
    "    compare_task_across_scales,\n",
    ")\n",
    "from src.visualization import (\n",
    "    plot_scale_trend, plot_scale_heatmap, plot_sp_overlay,\n",
    "    plot_per_task_scaling, plot_scale_dendrogram,\n",
    "    plot_cosine_similarity_matrix,\n",
    "    MODEL_SCALE_COLORS,\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Model Registry\n",
    "\n",
    "The Gemma 3 family spans 2 orders of magnitude in parameter count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_curve = gemma3_scaling_curve()\n",
    "\n",
    "print(f\"{'Model':<22s}  {'Params':>8s}  {'Layers':>6s}  {'Hidden':>6s}  {'log10(N)':>8s}  {'Transcoders':>11s}\")\n",
    "print('-' * 75)\n",
    "for spec in scaling_curve:\n",
    "    p_str = f\"{spec.n_params}M\" if spec.n_params < 1000 else f\"{spec.n_params // 1000}B\"\n",
    "    n_tc = len(spec.transcoders)\n",
    "    clt = any(t.is_clt for t in spec.transcoders)\n",
    "    tc_str = f\"{n_tc} ({'+ CLT' if clt else 'PLT only'})\"\n",
    "    print(f\"{spec.model_id:<22s}  {p_str:>8s}  {spec.n_layers:>6d}  {spec.hidden_dim:>6d}  {spec.log_params:>8.2f}  {tc_str:>11s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Load Scale Pipeline Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_dir = Path(\"../data/results/scale\")\n",
    "\n",
    "# Load model profiles\n",
    "profiles_path = scale_dir / \"scale_profiles.pkl\"\n",
    "if profiles_path.exists():\n",
    "    with open(profiles_path, \"rb\") as f:\n",
    "        model_profiles = pickle.load(f)\n",
    "    print(f\"Loaded profiles for {len(model_profiles)} model(s)\")\n",
    "    for model_id, mp in sorted(model_profiles.items()):\n",
    "        p = mp.model_spec.n_params\n",
    "        p_str = f\"{p}M\" if p < 1000 else f\"{p // 1000}B\"\n",
    "        print(f\"  {model_id} ({p_str}): {mp.n_total_graphs} graphs, {len(mp.task_profiles)} tasks\")\n",
    "        for task, tp in sorted(mp.task_profiles.items()):\n",
    "            print(f\"    {task}: {tp.n_graphs} graphs\")\n",
    "else:\n",
    "    print(f\"No scale profiles found at {profiles_path}\")\n",
    "    print(\"Run: python -m src.pipeline --scale-mode --n-random 100\")\n",
    "    model_profiles = {}\n",
    "\n",
    "# Load scale analysis JSON\n",
    "analysis_path = scale_dir / \"scale_analysis.json\"\n",
    "if analysis_path.exists():\n",
    "    with open(analysis_path) as f:\n",
    "        scale_analysis = json.load(f)\n",
    "    print(f\"\\nLoaded scale analysis summary\")\n",
    "else:\n",
    "    scale_analysis = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 3. Scale Heatmap — Main Result\n",
    "\n",
    "Mean Z-scores for each model size x motif class. This is the primary visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_profiles:\n",
    "    fig = plot_scale_heatmap(\n",
    "        model_profiles,\n",
    "        metric=\"z_score\",\n",
    "        title=\"Motif Z-Score Profile Across Model Scales\",\n",
    "        figsize=(16, max(4, len(model_profiles) * 1.2)),\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No model profiles loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 4. FFL Backbone Analysis\n",
    "\n",
    "The central question: is the feedforward loop (030T) universally enriched across all model scales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_profiles:\n",
    "    universal, ffl_details = check_ffl_backbone(model_profiles)\n",
    "    \n",
    "    print(f\"FFL universally enriched: {universal}\")\n",
    "    print()\n",
    "    print(f\"{'Model':<22s}  {'Mean Z':>7s}  {'Std Z':>7s}  {'Enriched':>8s}  {'N':>4s}\")\n",
    "    print('-' * 55)\n",
    "    for model_id in sorted(ffl_details.keys()):\n",
    "        d = ffl_details[model_id]\n",
    "        if d.get('mean_z') is not None:\n",
    "            print(f\"{model_id:<22s}  {d['mean_z']:>+7.2f}  {d['std_z']:>7.2f}  \"\n",
    "                  f\"{d['pct_enriched']:>7.1f}%  {d['n_total']:>4d}\")\n",
    "        else:\n",
    "            print(f\"{model_id:<22s}  {'N/A':>7s}\")\n",
    "    \n",
    "    # Plot FFL Z-score across scales\n",
    "    sorted_models = sorted(model_profiles.items(), key=lambda kv: kv[1].model_spec.n_params)\n",
    "    x = [mp.model_spec.log_params for _, mp in sorted_models]\n",
    "    y = [float(mp.overall_mean_z[MOTIF_FFL]) for _, mp in sorted_models]\n",
    "    y_std = [float(mp.overall_std_z[MOTIF_FFL]) for _, mp in sorted_models]\n",
    "    labels = [mid for mid, _ in sorted_models]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    colors = [MODEL_SCALE_COLORS.get(mid, 'gray') for mid in labels]\n",
    "    ax.errorbar(x, y, yerr=y_std, fmt='o-', color='#d62728', linewidth=2.5,\n",
    "                markersize=10, capsize=5, capthick=2, label='030T (FFL)')\n",
    "    for xi, yi, mid, c in zip(x, y, labels, colors):\n",
    "        ax.scatter([xi], [yi], c=c, s=100, zorder=5, edgecolors='black')\n",
    "    \n",
    "    ax.axhline(y=2.0, color='red', linestyle='--', alpha=0.3, label='Z = 2.0')\n",
    "    ax.axhline(y=0, color='black', linewidth=0.5)\n",
    "    \n",
    "    tick_labels = [f\"{mp.model_spec.n_params}M\" if mp.model_spec.n_params < 1000\n",
    "                   else f\"{mp.model_spec.n_params // 1000}B\" for _, mp in sorted_models]\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(tick_labels, fontsize=11)\n",
    "    ax.set_xlabel('Model Size', fontsize=12)\n",
    "    ax.set_ylabel('Mean Z-score', fontsize=12)\n",
    "    ax.set_title('FFL (030T) Enrichment Across Model Scales', fontsize=14, fontweight='bold')\n",
    "    ax.legend(fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No model profiles loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 5. Scaling Curves — Key Motifs vs log(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_profiles:\n",
    "    trends = compute_scale_trends(model_profiles, metric=\"z_score\")\n",
    "    \n",
    "    # Show key motifs\n",
    "    key_motifs = [MOTIF_FFL, MOTIF_CHAIN, MOTIF_FAN_IN, MOTIF_FAN_OUT, 5, 11]  # FFL, Chain, Fan-in, Fan-out, 111U, 030C\n",
    "    fig = plot_scale_trend(\n",
    "        trends,\n",
    "        motif_indices=key_motifs,\n",
    "        title=\"Key Motif Z-Scores Across Model Scales\",\n",
    "        figsize=(14, 7),\n",
    "    )\n",
    "    plt.show()\n",
    "    \n",
    "    # Print trend summary\n",
    "    print(f\"\\n{'Motif':<8s}  {'Direction':>10s}  {'Slope':>8s}  {'R²':>6s}  {'p-val':>8s}  {'ρ':>6s}  {'ρ p-val':>8s}\")\n",
    "    print('-' * 65)\n",
    "    for t in sorted(trends, key=lambda t: abs(t.slope), reverse=True):\n",
    "        if t.motif_index in CONNECTED_TRIAD_INDICES:\n",
    "            sig = \" *\" if t.is_significant else \"\"\n",
    "            print(f\"{t.motif_label:<8s}  {t.trend_direction:>10s}  {t.slope:>+8.3f}  {t.r_squared:>6.3f}  \"\n",
    "                  f\"{t.p_value:>8.4f}  {t.spearman_rho:>+6.3f}  {t.spearman_p:>8.4f}{sig}\")\n",
    "else:\n",
    "    print(\"No model profiles loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 6. Per-Task Scaling\n",
    "\n",
    "How do scaling patterns differ by task category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_profiles:\n",
    "    # Find common tasks\n",
    "    all_tasks = set()\n",
    "    for mp in model_profiles.values():\n",
    "        all_tasks.update(mp.task_profiles.keys())\n",
    "    common_tasks = sorted(all_tasks)\n",
    "    \n",
    "    for task_name in common_tasks[:4]:  # Show first 4 tasks\n",
    "        fig = plot_per_task_scaling(\n",
    "            model_profiles,\n",
    "            task_name,\n",
    "            motif_indices=[MOTIF_FFL, MOTIF_CHAIN, MOTIF_FAN_IN, MOTIF_FAN_OUT],\n",
    "            figsize=(12, 5),\n",
    "        )\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No model profiles loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 7. Phase Transition Detection\n",
    "\n",
    "Are there abrupt jumps in motif enrichment between adjacent model sizes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_profiles:\n",
    "    transitions = detect_phase_transitions(model_profiles, min_effect_size=1.0)\n",
    "    \n",
    "    if transitions:\n",
    "        print(f\"Found {len(transitions)} phase transition(s) (Cohen's d >= 1.0):\\n\")\n",
    "        print(f\"{'Motif':<8s}  {'At size':>10s}  {'Before':>8s}  {'After':>8s}  {'Cohen d':>8s}\")\n",
    "        print('-' * 50)\n",
    "        for pt in sorted(transitions, key=lambda t: t.effect_size, reverse=True)[:20]:\n",
    "            p_str = f\"{pt.transition_point}M\" if pt.transition_point < 1000 else f\"{pt.transition_point // 1000}B\"\n",
    "            print(f\"{pt.motif_label:<8s}  {p_str:>10s}  {pt.before_mean:>+8.2f}  {pt.after_mean:>+8.2f}  {pt.effect_size:>8.2f}\")\n",
    "    else:\n",
    "        print(\"No phase transitions detected (all changes gradual).\")\n",
    "else:\n",
    "    print(\"No model profiles loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 8. Model Similarity — Cosine Matrix & Dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_profiles and len(model_profiles) >= 2:\n",
    "    sim_matrix, model_names = pairwise_model_similarity(model_profiles)\n",
    "    \n",
    "    fig = plot_cosine_similarity_matrix(\n",
    "        sim_matrix, model_names,\n",
    "        title=\"Model Cosine Similarity (SP Vectors)\",\n",
    "        figsize=(8, 7),\n",
    "    )\n",
    "    plt.show()\n",
    "    \n",
    "    # Run full comparison for dendrogram\n",
    "    result = run_scale_comparison(model_profiles)\n",
    "    if result.linkage_matrix.size > 0:\n",
    "        fig = plot_scale_dendrogram(\n",
    "            result.linkage_matrix,\n",
    "            result.model_names,\n",
    "            title=\"Model Similarity Dendrogram (Cosine Distance on SP Vectors)\",\n",
    "        )\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Need at least 2 model profiles for similarity analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 9. SP Overlay — All Models' Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_profiles:\n",
    "    fig = plot_sp_overlay(\n",
    "        model_profiles,\n",
    "        title=\"Significance Profiles Across Gemma 3 Scales\",\n",
    "        figsize=(18, 7),\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No model profiles loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## 10. Comparison with Haiku / Gemma-2-2B / Qwen3-4B Baseline\n",
    "\n",
    "If the original Haiku pipeline results exist, compare the Gemma 3 scaling\n",
    "profiles against the original Haiku/Gemma-2/Qwen3 baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original pipeline task profiles for comparison\n",
    "original_profiles_path = Path(\"../data/results/task_profiles.pkl\")\n",
    "if original_profiles_path.exists() and model_profiles:\n",
    "    with open(original_profiles_path, \"rb\") as f:\n",
    "        original_profiles = pickle.load(f)\n",
    "    \n",
    "    # Compare overall mean Z-scores\n",
    "    print(\"Original Haiku analysis (99 graphs):\")\n",
    "    for task, tp in sorted(original_profiles.items()):\n",
    "        print(f\"  {task}: {tp.n_graphs} graphs, mean |Z| = {np.mean(np.abs(tp.mean_z)):.2f}\")\n",
    "    \n",
    "    # Build aggregate profile for Haiku\n",
    "    all_sp = []\n",
    "    all_z = []\n",
    "    for tp in original_profiles.values():\n",
    "        all_sp.extend(tp.sp_vectors)\n",
    "        all_z.extend(tp.z_score_vectors)\n",
    "    \n",
    "    if all_z:\n",
    "        haiku_mean_z = np.array(all_z).mean(axis=0)\n",
    "        \n",
    "        # Compare with each Gemma 3 model\n",
    "        motif_labels = [TRIAD_LABELS[i] for i in CONNECTED_TRIAD_INDICES]\n",
    "        print(f\"\\n{'Motif':<8s}  {'Haiku':>8s}\", end='')\n",
    "        for mid, mp in sorted(model_profiles.items(), key=lambda kv: kv[1].model_spec.n_params):\n",
    "            p = mp.model_spec.n_params\n",
    "            label = f\"{p}M\" if p < 1000 else f\"{p // 1000}B\"\n",
    "            print(f\"  {label:>8s}\", end='')\n",
    "        print()\n",
    "        print('-' * (18 + 10 * len(model_profiles)))\n",
    "        \n",
    "        for idx in CONNECTED_TRIAD_INDICES:\n",
    "            label = TRIAD_LABELS[idx]\n",
    "            print(f\"{label:<8s}  {haiku_mean_z[idx]:>+8.2f}\", end='')\n",
    "            for mid, mp in sorted(model_profiles.items(), key=lambda kv: kv[1].model_spec.n_params):\n",
    "                if len(mp.overall_mean_z) > idx:\n",
    "                    print(f\"  {mp.overall_mean_z[idx]:>+8.2f}\", end='')\n",
    "                else:\n",
    "                    print(f\"  {'N/A':>8s}\", end='')\n",
    "            print()\n",
    "else:\n",
    "    if not model_profiles:\n",
    "        print(\"No model profiles loaded.\")\n",
    "    else:\n",
    "        print(f\"Original profiles not found at {original_profiles_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
